{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8/30/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: fastrag 3.0.2\n",
      "Uninstalling fastrag-3.0.2:\n",
      "  Would remove:\n",
      "    /opt/anaconda3/envs/colbert/lib/python3.8/site-packages/fastrag-3.0.2.dist-info/*\n",
      "    /opt/anaconda3/envs/colbert/lib/python3.8/site-packages/fastrag/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall fastrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Essential imports for loading components and modifications to original Haystack components\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generators, rankers, retrievers, stores\n\u001b[1;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaudi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaudiGenerator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPEXGenerator\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlavaHFGenerator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenVINOGenerator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTGenerator\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m     bytes_io \u001b[38;5;241m=\u001b[39m BytesIO(base64\u001b[38;5;241m.\u001b[39mb64decode(base_64_input))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(bytes_io)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLlavaHFGenerator\u001b[39;00m(HuggingFaceLocalGenerator):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Generator based on a Llava Hugging Face model loaded.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    The original Llava model: https://github.com/haotian-liu/LLaVA\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         stop_words: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:119\u001b[0m, in \u001b[0;36mLlavaHFGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<image>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@component\u001b[39m\u001b[38;5;241m.\u001b[39moutput_types(replies\u001b[38;5;241m=\u001b[39mList[\u001b[38;5;28mstr\u001b[39m])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    118\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m--> 119\u001b[0m     images: \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     generation_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m ):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Run the text generation model on the given prompt.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        - raw_images: A list of the raw PIL images.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import fastrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Essential imports for loading components and modifications to original Haystack components\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generators, rankers, retrievers, stores\n\u001b[1;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaudi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaudiGenerator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPEXGenerator\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlavaHFGenerator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenVINOGenerator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTGenerator\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m     bytes_io \u001b[38;5;241m=\u001b[39m BytesIO(base64\u001b[38;5;241m.\u001b[39mb64decode(base_64_input))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(bytes_io)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLlavaHFGenerator\u001b[39;00m(HuggingFaceLocalGenerator):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Generator based on a Llava Hugging Face model loaded.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    The original Llava model: https://github.com/haotian-liu/LLaVA\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         stop_words: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:119\u001b[0m, in \u001b[0;36mLlavaHFGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<image>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@component\u001b[39m\u001b[38;5;241m.\u001b[39moutput_types(replies\u001b[38;5;241m=\u001b[39mList[\u001b[38;5;28mstr\u001b[39m])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    118\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m--> 119\u001b[0m     images: \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     generation_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m ):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Run the text generation model on the given prompt.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        - raw_images: A list of the raw PIL images.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import fastrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrag.stores import PLAIDDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/colbert/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Essential imports for loading components and modifications to original Haystack components\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generators, rankers, retrievers, stores\n\u001b[1;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaudi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaudiGenerator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPEXGenerator\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlavaHFGenerator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenVINOGenerator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTGenerator\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m     bytes_io \u001b[38;5;241m=\u001b[39m BytesIO(base64\u001b[38;5;241m.\u001b[39mb64decode(base_64_input))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(bytes_io)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLlavaHFGenerator\u001b[39;00m(HuggingFaceLocalGenerator):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Generator based on a Llava Hugging Face model loaded.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    The original Llava model: https://github.com/haotian-liu/LLaVA\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         stop_words: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:119\u001b[0m, in \u001b[0;36mLlavaHFGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<image>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@component\u001b[39m\u001b[38;5;241m.\u001b[39moutput_types(replies\u001b[38;5;241m=\u001b[39mList[\u001b[38;5;28mstr\u001b[39m])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    118\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m--> 119\u001b[0m     images: \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     generation_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m ):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Run the text generation model on the given prompt.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        - raw_images: A list of the raw PIL images.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#\n",
    "import fastrag, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.tsv' with the path to your TSV file\n",
    "file_path = '/Users/49280549/Library/CloudStorage/Box-Box/xGenAI-Jane/collection.tsv'\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Show the structure of the DataFrame\n",
    "print(\"DataFrame Structure:\")\n",
    "print(df.info())\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(\"/Users/49280549/Library/CloudStorage/Box-Box/xGenAI-Jane/code/data/ssrn_data.csv\")\n",
    "df1=df1[['id','title','year','authors','abstract','journal-ref','keywords']]\n",
    "file_path = '/Users/49280549/Library/CloudStorage/Box-Box/xGenAI-Jane/Data/ssrn_data2.json'\n",
    "\n",
    "# Read the JSON Lines file into a DataFrame\n",
    "df2 = pd.read_json(file_path, lines=True)\n",
    "df2=df2[['id','title','date','authors','abstract','journal-ref','keywords']]\n",
    "df2.rename(columns={'date': 'year'}, inplace=True)\n",
    "import re\n",
    "\n",
    "def extract_date(date_str):\n",
    "    # Regular expression to find the date format (e.g., '23 May 2024')\n",
    "    match = re.search(r'\\d{1,2} \\b\\w{3}\\b \\d{4}', date_str)\n",
    "    if match:\n",
    "        return match.group(0)  # Return the matched date string\n",
    "    else:\n",
    "        return None  # Return None if no date found\n",
    "\n",
    "# Apply the function to the 'date' column\n",
    "df2['year'] = df2['year'].apply(extract_date)\n",
    "\n",
    "# Convert the cleaned date to datetime and extract the year\n",
    "df2['year'] = pd.to_datetime(df2['year'], format='%d %b %Y', errors='coerce').dt.year\n",
    "df = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_two=df[['id','abstract']]\n",
    "df_two = df_two.drop_duplicates()\n",
    "df_two.to_csv('df_two.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: colbert in /Users/49280549/Library/Python/3.9/lib/python/site-packages (0.40)\n",
      "Requirement already satisfied: icalendar in /Users/49280549/Library/Python/3.9/lib/python/site-packages (from colbert) (5.0.13)\n",
      "Requirement already satisfied: pytz in /Users/49280549/Library/Python/3.9/lib/python/site-packages (from colbert) (2022.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/49280549/Library/Python/3.9/lib/python/site-packages (from icalendar->colbert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil->icalendar->colbert) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert import Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PLAIDDocumentStore\n\u001b[1;32m      2\u001b[0m store \u001b[38;5;241m=\u001b[39m PLAIDDocumentStore(index_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                            checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/49280549/Library/CloudStorage/Box-Box/xGenAI-Jane/colbertv2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                            collection_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_two.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Essential imports for loading components and modifications to original Haystack components\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generators, rankers, retrievers, stores\n\u001b[1;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaudi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaudiGenerator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IPEXGenerator\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllava\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlavaHFGenerator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenVINOGenerator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTGenerator\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m     bytes_io \u001b[38;5;241m=\u001b[39m BytesIO(base64\u001b[38;5;241m.\u001b[39mb64decode(base_64_input))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(bytes_io)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLlavaHFGenerator\u001b[39;00m(HuggingFaceLocalGenerator):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Generator based on a Llava Hugging Face model loaded.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    The original Llava model: https://github.com/haotian-liu/LLaVA\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         stop_words: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/GitHub/fastRAG/fastrag/generators/llava.py:119\u001b[0m, in \u001b[0;36mLlavaHFGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<image>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@component\u001b[39m\u001b[38;5;241m.\u001b[39moutput_types(replies\u001b[38;5;241m=\u001b[39mList[\u001b[38;5;28mstr\u001b[39m])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    118\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m--> 119\u001b[0m     images: \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     generation_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    121\u001b[0m ):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Run the text generation model on the given prompt.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        - raw_images: A list of the raw PIL images.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from fastrag.stores import PLAIDDocumentStore\n",
    "store = PLAIDDocumentStore(index_path=\"/index\",\n",
    "                           checkpoint_path=\"/Users/49280549/Library/CloudStorage/Box-Box/xGenAI-Jane/colbertv2.0\",\n",
    "                           collection_path=\"df_two.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
