{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successful Run - optimized reranker.\n",
    "https://huggingface.co/BAAI/bge-small-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"There is a blue house on Oxford street.\",\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"fastRAG had its first commit in 2022.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i, d in enumerate(examples):\n",
    "    documents.append(Document(content=d, id=(i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrag.embedders import IPEXSentenceTransformersDocumentEmbedder, IPEXSentenceTransformersTextEmbedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedder = IPEXSentenceTransformersTextEmbedder(model=\"BAAI/bge-small-en-v1.5\", batch_size=1, max_seq_length=512, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder = IPEXSentenceTransformersDocumentEmbedder(model=\"BAAI/bge-small-en-v1.5\", batch_size=32, max_seq_length=512, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.intel import IPEXModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder.warm_up(); query_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(documents)[\"documents\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.write_documents(docs_with_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = InMemoryEmbeddingRetriever(document_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.17it/s]\n"
     ]
    }
   ],
   "source": [
    "query_vec = query_embedder.run(\"What is Paris?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id=2, content: 'Paris is the capital of France.', score: 0.8089880155487852)]\n"
     ]
    }
   ],
   "source": [
    "print(retriever.run(query_vec['embedding'], top_k=1)['documents'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Re-ranker and Running a Pipeline\n",
    "We can add an optimized ranker to re-order the documents coming from the retriever. Note that this is component has no dependencies on the previous retrieval steps. It takes the document content and query, and encodes all to vectors to be re-ordered by ordering the similarities in a descending order.\n",
    "\n",
    "We build a pipeline to automate the previous sections where we had to manually embed queries before doing retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrag.rankers import IPEXBiEncoderSimilarityRanker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = IPEXBiEncoderSimilarityRanker(\"BAAI/bge-small-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"embedder\", query_embedder)\n",
    "pipe.add_component(\"ranker\", ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x1629eb8b0>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - embedder: IPEXSentenceTransformersTextEmbedder\n",
       "  - ranker: IPEXBiEncoderSimilarityRanker\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> ranker.documents (List[Document])\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.connect(\"embedder\", \"retriever\")\n",
    "pipe.connect(\"retriever\", \"ranker.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Paris?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.75it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 53.80it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 56.22it/s]\n"
     ]
    }
   ],
   "source": [
    "result = pipe.run(\n",
    "    {\n",
    "        \"embedder\": {\"text\": query},\n",
    "        \"ranker\": {\"query\": query},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id=2, content: 'Paris is the capital of France.', score: 0.8089880155487852, embedding: vector of size 384), Document(id=1, content: 'There is a blue house on Oxford street.', score: 0.46183047966466195, embedding: vector of size 384), Document(id=3, content: 'fastRAG had its first commit in 2022.', score: 0.37713187846290086, embedding: vector of size 384)]\n"
     ]
    }
   ],
   "source": [
    "print(result['ranker']['documents'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
